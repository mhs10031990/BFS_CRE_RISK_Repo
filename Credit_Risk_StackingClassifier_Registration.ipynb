{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a362d7",
   "metadata": {},
   "source": [
    "# Use Credit Risk Analytics Notebook Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32837b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection manager service url initialised to http://fdc-project-manager:80/project-manager\n",
      "If you need to update its value then update the variable CONNECTION_MANAGER_BASE_URL in os env.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'appengine' from 'urllib3.contrib' (/packages/Python-3.8-Snowpark/c4077b7c-1484-4474-902b-4157253dda0a/3.8/urllib3/contrib/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/c4077b7c-1484-4474-902b-4157253dda0a/3.8/requests_toolbelt/_compat.py:48\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackages\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01murllib3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m appengine \u001b[38;5;28;01mas\u001b[39;00m gaecontrib\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'appengine' from 'requests.packages.urllib3.contrib' (/packages/Python-3.8-Snowpark/c4077b7c-1484-4474-902b-4157253dda0a/3.8/urllib3/contrib/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# FosforML to register Model on FDC\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dump, load\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfosforml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfosforml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MLModelFlavours\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/c4077b7c-1484-4474-902b-4157253dda0a/3.8/fosforml/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     add_version,\n\u001b[1;32m      5\u001b[0m     apply_model_strategy,\n\u001b[1;32m      6\u001b[0m     build_time_metrics,\n\u001b[1;32m      7\u001b[0m     delete_model,\n\u001b[1;32m      8\u001b[0m     deploy_model,\n\u001b[1;32m      9\u001b[0m     describe_model,\n\u001b[1;32m     10\u001b[0m     describe_model_using_model_name,\n\u001b[1;32m     11\u001b[0m     ensemble_model_list,\n\u001b[1;32m     12\u001b[0m     fetch_model_resources,\n\u001b[1;32m     13\u001b[0m     generate_schema,\n\u001b[1;32m     14\u001b[0m     get_model_info,\n\u001b[1;32m     15\u001b[0m     get_model_profiling,\n\u001b[1;32m     16\u001b[0m     list_models,\n\u001b[1;32m     17\u001b[0m     load_model,\n\u001b[1;32m     18\u001b[0m     load_train_and_test_data,\n\u001b[1;32m     19\u001b[0m     promote_model,\n\u001b[1;32m     20\u001b[0m     register_ensemble_model,\n\u001b[1;32m     21\u001b[0m     register_model,\n\u001b[1;32m     22\u001b[0m     stop_model,\n\u001b[1;32m     23\u001b[0m     update_existing_model,\n\u001b[1;32m     24\u001b[0m     update_metadata_info,\n\u001b[1;32m     25\u001b[0m     update_model_details,\n\u001b[1;32m     26\u001b[0m     update_version_details,\n\u001b[1;32m     27\u001b[0m     fetch_feedback_accuracy,\n\u001b[1;32m     28\u001b[0m     delete_model_version,\n\u001b[1;32m     29\u001b[0m     add_artifacts,\n\u001b[1;32m     30\u001b[0m     download_artifacts,\n\u001b[1;32m     31\u001b[0m     get_model_obj\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfosforml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwidgets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregister_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RegisterModel\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scoring_func\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/c4077b7c-1484-4474-902b-4157253dda0a/3.8/fosforml/api.py:21\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmosaic_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mencoding_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base64_encode\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmosaic_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     create_model_tar,\n\u001b[1;32m     17\u001b[0m     extract_tar,\n\u001b[1;32m     18\u001b[0m     pickle_dumps,\n\u001b[1;32m     19\u001b[0m     pickle_loads,\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrequests_toolbelt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultipart\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mencoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultipartEncoder\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m     MLModelArtifactsV1,\n\u001b[1;32m     25\u001b[0m     MLModelDeployV1,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     MLKYDDataStoreV1,\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scoring_func\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/c4077b7c-1484-4474-902b-4157253dda0a/3.8/requests_toolbelt/__init__.py:12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mrequests-toolbelt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m=================\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m:license: Apache v2.0, see LICENSE for more details\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madapters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SSLAdapter, SourceAddressAdapter\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauth\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GuessAuth\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultipart\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     MultipartEncoder, MultipartEncoderMonitor, MultipartDecoder,\n\u001b[1;32m     16\u001b[0m     ImproperBodyPartContentException, NonMultipartContentTypeException\n\u001b[1;32m     17\u001b[0m     )\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/c4077b7c-1484-4474-902b-4157253dda0a/3.8/requests_toolbelt/adapters/__init__.py:12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mrequests-toolbelt.adapters\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m==========================\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m:license: Apache v2.0, see LICENSE for more details\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mssl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SSLAdapter\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msource\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SourceAddressAdapter\n\u001b[1;32m     15\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSSLAdapter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSourceAddressAdapter\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/c4077b7c-1484-4474-902b-4157253dda0a/3.8/requests_toolbelt/adapters/ssl.py:16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madapters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPAdapter\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m poolmanager\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSSLAdapter\u001b[39;00m(HTTPAdapter):\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    A HTTPS Adapter for Python Requests that allows the choice of the SSL/TLS\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    version negotiated by Requests. This can be used either to enforce the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m    properly when used with proxies.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/packages/Python-3.8-Snowpark/c4077b7c-1484-4474-902b-4157253dda0a/3.8/requests_toolbelt/_compat.py:50\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackages\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01murllib3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m appengine \u001b[38;5;28;01mas\u001b[39;00m gaecontrib\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m appengine \u001b[38;5;28;01mas\u001b[39;00m gaecontrib\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m requests\u001b[38;5;241m.\u001b[39m__build__ \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0x021200\u001b[39m:\n\u001b[1;32m     53\u001b[0m     PyOpenSSLContext \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'appengine' from 'urllib3.contrib' (/packages/Python-3.8-Snowpark/c4077b7c-1484-4474-902b-4157253dda0a/3.8/urllib3/contrib/__init__.py)"
     ]
    }
   ],
   "source": [
    "from snowflake.snowpark import Session\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "# Data Science Libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from math import sqrt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostClassifier\n",
    "import gc\n",
    "\n",
    "import configparser\n",
    "\n",
    "# FosforIO to read data from Snowflake\n",
    "from fosforio import snowflake\n",
    "# FosforML to register Model on FDC\n",
    "from joblib import dump, load\n",
    "from fosforml import *\n",
    "from fosforml.constants import MLModelFlavours\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8078d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NFOLDS = 3\n",
    "SEED = 0\n",
    "NROWS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b65555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get snowflake connection object with a default snowflake connection created by the user, if available.\n",
    "#snowflake.get_connection()\n",
    "\n",
    "# To get snowflake connection object with a specific connection name\n",
    "snowflake.get_connection(connection_name=\"FDC_Banking_FS_Snowflake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebc2b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train_sf  = snowflake.get_dataframe(\"CRA_APPLICATION_TRAIN_DETAILS\")\n",
    "application_test_sf  = snowflake.get_dataframe(\"CRA_APPLICATION_TEST_DETAILS\")\n",
    "previous_application_sf  = snowflake.get_dataframe(\"CRA_PREVIOUS_APPLICATION_DETAILS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0b4b30",
   "metadata": {},
   "source": [
    "# Convert Snowflake data into Pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b65c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = application_train_sf.copy()\n",
    "test = application_test_sf.copy()\n",
    "prev = previous_application_sf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ded794",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['CREATED_BY','CREATED_AT'], axis=1, inplace=True)\n",
    "test.drop(['CREATED_BY','CREATED_AT'], axis=1, inplace=True)\n",
    "prev.drop(['CREATED_BY','CREATED_AT'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1a2832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categorical_feats = [\n",
    "    f for f in data.columns if data[f].dtype == 'object'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f1651c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_ in categorical_feats:\n",
    "    data[f_], indexer = pd.factorize(data[f_])\n",
    "    test[f_] = indexer.get_indexer(test[f_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d8cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.enable()\n",
    "\n",
    "y_train = data['TARGET']\n",
    "del data['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77babae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_cat_features = [\n",
    "    f_ for f_ in prev.columns if prev[f_].dtype == 'object'\n",
    "]\n",
    "for f_ in prev_cat_features:\n",
    "    prev[f_], _ = pd.factorize(prev[f_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f752203",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_prev = prev.groupby('SK_ID_CURR').mean()\n",
    "cnt_prev = prev[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "avg_prev['nb_app'] = cnt_prev['SK_ID_PREV']\n",
    "del avg_prev['SK_ID_PREV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87527ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data.merge(right=avg_prev.reset_index(), how='left', on='SK_ID_CURR')\n",
    "x_test = test.merge(right=avg_prev.reset_index(), how='left', on='SK_ID_CURR')\n",
    "\n",
    "x_train = x_train.fillna(0)\n",
    "x_test= x_test.fillna(0)\n",
    "\n",
    "ntrain = x_train.shape[0]\n",
    "ntest = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e01200",
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_feats = ['SK_ID_CURR']\n",
    "features = [f_ for f_ in x_train.columns if f_ not in excluded_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d847db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[features]\n",
    "x_test = x_test[features]\n",
    "\n",
    "kf = KFold(n_splits = NFOLDS, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab19ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return self.clf.predict_proba(x)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a44758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatboostWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_seed'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return self.clf.predict_proba(x)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3a5d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XgbWrapper(object):\n",
    "    def __init__(self, seed=0, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 250)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.gbdt.predict(xgb.DMatrix(x))\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return self.gbdt.predict_proba(xgb.DMatrix(x))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604c71ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clf):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x_train)):\n",
    "        x_tr = x_train.loc[train_index]\n",
    "        y_tr = y_train.loc[train_index]\n",
    "        x_te = x_train.loc[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5f6e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_params = {\n",
    "    'n_jobs': 16,\n",
    "    'n_estimators': 200,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'min_samples_leaf': 2,\n",
    "    'random_state':0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee53240",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    'n_jobs': 16,\n",
    "    'n_estimators': 200,\n",
    "    'max_features': 0.2,\n",
    "    'max_depth': 12,\n",
    "    'min_samples_leaf': 2,\n",
    "    'random_state':0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78415a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'seed': 0,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.075,\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 4,\n",
    "    'num_parallel_tree': 1,\n",
    "    'min_child_weight': 1,\n",
    "    'nrounds': 200\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14272538",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_params = {\n",
    "    'iterations': 200,\n",
    "    'learning_rate': 0.5,\n",
    "    'depth': 3,\n",
    "    'l2_leaf_reg': 40,\n",
    "    'bootstrap_type': 'Bernoulli',\n",
    "    'subsample': 0.7,\n",
    "    'scale_pos_weight': 5,\n",
    "    'eval_metric': 'AUC',\n",
    "    'od_type': 'Iter',\n",
    "    'allow_writing_files': False,\n",
    "    'random_seed':0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb755482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xg = XgbWrapper(seed=SEED, params=xgb_params)\n",
    "#et = SklearnWrapper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "#rf = SklearnWrapper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "#cb = CatboostWrapper(clf= CatBoostClassifier, seed = SEED, params=catboost_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35afc22b",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093fa990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xg_oof_train, xg_oof_test = get_oof(xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eaec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = xgb_params\n",
    "param['seed'] = 0\n",
    "nrounds = 250\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "gbdt = xgb.train(param, dtrain, nrounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e63135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_prob = gbdt.predict(xgb.DMatrix(x))\n",
    "#y_pred = np.round(y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c85f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = gbdt.predict(xgb.DMatrix(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9007befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68b7eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c44ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c152d938",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scoring_func\n",
    "def score(model, request):\n",
    "    payload_dict = request.json[\"payload\"]\n",
    "    data = pd.DataFrame(payload_dict,index=[0])\n",
    "    y_pred = model.predict(xgb.DMatrix(data))\n",
    "    #y_prob = model.predict_proba(xgb.DMatrix(data))[:,1]\n",
    "    temp_dict = {\"Prediction: \": np.round(y_pred), \"Probability: \": y_pred }\n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ec086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload  = x_train.iloc[0].to_dict()\n",
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9c9e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('{ \"payload\": ', payload, \"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3765ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.Request()\n",
    "req.json = {\"payload\":payload}\n",
    "y_req = req\n",
    "score(gbdt, y_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8ece8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## registering the model in Fosfor.\n",
    "model_reg = register_model(gbdt,\n",
    "               score, \n",
    "               name=\"Credit_Risk_XGB_Classifier\", \n",
    "               description=\"Credit Risk XGBoost Classification Model\",\n",
    "               flavour=MLModelFlavours.sklearn,\n",
    "               model_type=\"classification\",\n",
    "               #init_script=\"pip install snowflake-ml-python==1.0.11\",\n",
    "               init_script=\"pip install scikit-learn==1.2.1\",                           \n",
    "               y_true=y_train,\n",
    "               y_pred=y_pred,\n",
    "               prob=y_prob,\n",
    "               features=x_train.columns,\n",
    "               input_type=\"json\", \n",
    "               explain_ai=True,\n",
    "               x_train=x_train, \n",
    "               x_test=x_train, \n",
    "               y_train=y_train.tolist(),\n",
    "               y_test=y_train.tolist(),\n",
    "               feature_names=x_train.columns.tolist(),\n",
    "               original_features=x_train.columns.tolist(),\n",
    "               feature_ids=x_train.columns,\n",
    "               kyd=True, kyd_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60a1ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/Output/CreditRisk_XGBclassifier_v1.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(gbdt, f) # serialize the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('model_artifacts/CreditRisk_XGBclassifier_v1.pkl', 'wb') as f:  # open a text file\n",
    "#    pickle.dump(gbdt, f) # serialize the list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dcbb98",
   "metadata": {},
   "source": [
    "# RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfcb49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier(**rf_params)\n",
    "RFC.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52da9fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = RFC.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c96ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = RFC.predict_proba(x_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7ab750",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706dc9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01269a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scoring_func\n",
    "def score(model, request):\n",
    "    payload_dict = request.json[\"payload\"]\n",
    "    data = pd.DataFrame(payload_dict,index=[0])\n",
    "    y_pred = model.predict(data)\n",
    "    y_prob = model.predict_proba(data)[:,1]\n",
    "    temp_dict = {\"Prediction: \": np.round(y_pred), \"Probability: \": y_prob }\n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7126ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload  = x_train.iloc[0].to_dict()\n",
    "print ('{ \"payload\": ', payload, \"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aa2fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.Request()\n",
    "req.json = {\"payload\":payload}\n",
    "y_req = req\n",
    "score(RFC, y_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8084fa0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## registering the model in Fosfor.\n",
    "model_reg = register_model(RFC,\n",
    "               score, \n",
    "               name=\"Credit_Risk_RandomForest_Classifier\", \n",
    "               description=\"Credit Risk RandomForest Classification Model\",\n",
    "               flavour=MLModelFlavours.sklearn,\n",
    "               model_type=\"classification\",\n",
    "               #init_script=\"pip install snowflake-ml-python==1.0.11\",\n",
    "               init_script=\"pip install scikit-learn==1.2.1\",   \n",
    "               y_true=y_train,\n",
    "               y_pred=y_pred,\n",
    "               prob=y_prob,\n",
    "               features=x_train.columns,\n",
    "               input_type=\"json\", \n",
    "               explain_ai=True,\n",
    "               x_train=x_train, \n",
    "               x_test=x_train, \n",
    "               y_train=y_train.tolist(),\n",
    "               y_test=y_train.tolist(),\n",
    "               feature_names=x_train.columns.tolist(),\n",
    "               original_features=x_train.columns.tolist(),\n",
    "               feature_ids=x_train.columns,\n",
    "               kyd=True, kyd_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af8fe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/Output/CreditRisk_RFclassifier_v1.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(RFC, f) # serialize the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d22936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('model_artifacts/CreditRisk_RFclassifier_v1.pkl', 'wb') as f:  # open a text file\n",
    "#    pickle.dump(RFC, f) # serialize the list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b3973f",
   "metadata": {},
   "source": [
    "# Extra Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a6fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETC = ExtraTreesClassifier(**et_params)\n",
    "ETC.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c48cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ETC.predict(x_train)\n",
    "y_prob = ETC.predict_proba(x_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea815ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cad9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5895e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scoring_func\n",
    "def score(model, request):\n",
    "    payload_dict = request.json[\"payload\"]\n",
    "    data = pd.DataFrame(payload_dict,index=[0])\n",
    "    y_pred = model.predict(data)\n",
    "    y_prob = model.predict_proba(data)[:,1]\n",
    "    temp_dict = {\"Prediction: \": np.round(y_pred), \"Probability: \": y_prob }\n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb64b470",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload  = x_train.iloc[0].to_dict()\n",
    "print ('{ \"payload\": ', payload, \"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508f0d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.Request()\n",
    "req.json = {\"payload\":payload}\n",
    "y_req = req\n",
    "score(ETC, y_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40db2b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## registering the model in Fosfor.\n",
    "model_reg = register_model(ETC,\n",
    "               score, \n",
    "               name=\"Credit_Risk_ExtraTree_Classifier\", \n",
    "               description=\"Credit Risk ExtraTree Classification Model\",\n",
    "               flavour=MLModelFlavours.sklearn,\n",
    "               model_type=\"classification\",\n",
    "               #init_script=\"pip install snowflake-ml-python==1.0.11\",\n",
    "               init_script=\"pip install scikit-learn==1.2.1\",   \n",
    "               y_true=y_train,\n",
    "               y_pred=y_pred,\n",
    "               prob=y_prob,\n",
    "               features=x_train.columns,\n",
    "               input_type=\"json\", \n",
    "               explain_ai=True,\n",
    "               x_train=x_train, \n",
    "               x_test=x_train, \n",
    "               y_train=y_train.tolist(),\n",
    "               y_test=y_train.tolist(),\n",
    "               feature_names=x_train.columns.tolist(),\n",
    "               original_features=x_train.columns.tolist(),\n",
    "               feature_ids=x_train.columns,\n",
    "               kyd=True, kyd_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f43526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/Output/CreditRisk_ETclassifier_v1.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(ETC, f) # serialize the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99735ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('model_artifacts/CreditRisk_ETclassifier_v1.pkl', 'wb') as f:  # open a text file\n",
    "#    pickle.dump(ETC, f) # serialize the list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ce7ac8",
   "metadata": {},
   "source": [
    "# CATBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e374b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "CBC = CatBoostClassifier(**catboost_params)\n",
    "CBC.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794e860",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = CBC.predict(x_train)\n",
    "y_prob = CBC.predict_proba(x_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064e3c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f73dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea82d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scoring_func\n",
    "def score(model, request):\n",
    "    payload_dict = request.json[\"payload\"]\n",
    "    data = pd.DataFrame(payload_dict,index=[0])\n",
    "    y_pred = model.predict(data)\n",
    "    y_prob = model.predict_proba(data)[:,1]\n",
    "    temp_dict = {\"Prediction: \": np.round(y_pred), \"Probability: \": y_prob }\n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8583889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload  = x_train.iloc[0].to_dict()\n",
    "print ('{ \"payload\": ', payload, \"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec03f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.Request()\n",
    "req.json = {\"payload\":payload}\n",
    "y_req = req\n",
    "score(CBC, y_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f69e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## registering the model in Fosfor.\n",
    "model_reg = register_model(CBC,\n",
    "               score, \n",
    "               name=\"Credit_Risk_CATBoost_Classifier\", \n",
    "               description=\"Credit Risk CatBoost Classification Model\",\n",
    "               flavour=MLModelFlavours.sklearn,\n",
    "               model_type=\"classification\",\n",
    "               #init_script=\"pip install snowflake-ml-python==1.0.11\",\n",
    "               init_script=\"pip install scikit-learn==1.2.1\",   \n",
    "               y_true=y_train,\n",
    "               y_pred=y_pred,\n",
    "               prob=y_prob,\n",
    "               features=x_train.columns,\n",
    "               input_type=\"json\", \n",
    "               explain_ai=True,\n",
    "               x_train=x_train, \n",
    "               x_test=x_train, \n",
    "               y_train=y_train.tolist(),\n",
    "               y_test=y_train.tolist(),\n",
    "               feature_names=x_train.columns.tolist(),\n",
    "               original_features=x_train.columns.tolist(),\n",
    "               feature_ids=x_train.columns,\n",
    "               kyd=True, kyd_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6179acd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/Output/CreditRisk_CatBoostclassifier_v1.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(CBC, f) # serialize the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc23d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('model_artifacts/CreditRisk_CatBoostclassifier_v1.pkl', 'wb') as f:  # open a text file\n",
    "#    pickle.dump(CBC, f) # serialize the list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5ee9bf",
   "metadata": {},
   "source": [
    "# Version 1 of Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de51e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_XGB = gbdt.predict(xgb.DMatrix(x_train))\n",
    "x_train_RFC = RFC.predict_proba(x_train)[:,1]\n",
    "x_train_ETC = ETC.predict_proba(x_train)[:,1]\n",
    "x_train_CBC = CBC.predict_proba(x_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8874b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_XGB = gbdt.predict(xgb.DMatrix(x_test))\n",
    "x_test_RFC = RFC.predict_proba(x_test)[:,1]\n",
    "x_test_ETC = ETC.predict_proba(x_test)[:,1]\n",
    "x_test_CBC = CBC.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8883f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_XGBT = x_train_XGB.reshape(-1,1)\n",
    "x_train_RFCT = x_train_RFC.reshape(-1,1)\n",
    "x_train_ETCT = x_train_ETC.reshape(-1,1)\n",
    "x_train_CBCT = x_train_CBC.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29974030",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_stk = np.concatenate((x_train_XGBT, x_train_RFCT, x_train_ETCT, x_train_CBCT),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de8ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_stk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bdb968",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_XGBT = x_test_XGB.reshape(-1,1)\n",
    "x_test_RFCT = x_test_RFC.reshape(-1,1)\n",
    "x_test_ETCT = x_test_ETC.reshape(-1,1)\n",
    "x_test_CBCT = x_test_CBC.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34abf5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_stk = np.concatenate((x_test_XGBT, x_test_RFCT, x_test_ETCT, x_test_CBCT),axis=1)\n",
    "x_test_stk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9a9b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_Stack = RandomForestClassifier()\n",
    "RFC_Stack.fit(x_train_stk,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3aa01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stk = RFC_Stack.predict(x_train_stk)\n",
    "y_prob_stk = RFC_Stack.predict_proba(x_train_stk)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f7eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_pred_stk = RFC_Stack.predict(x_test_stk)\n",
    "ytest_prob_stk = RFC_Stack.predict_proba(x_test_stk)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bacd8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f62f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_stk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76efbe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scoring_func\n",
    "def score(model, request):\n",
    "    payload_dict = request.json[\"payload\"]\n",
    "    data = pd.DataFrame(payload_dict,index=[0])\n",
    "    \n",
    "    data_XGB = gbdt.predict(xgb.DMatrix(data))\n",
    "    data_RFC = RFC.predict_proba(data)[:,1]\n",
    "    data_ETC = ETC.predict_proba(data)[:,1]\n",
    "    data_CBC = CBC.predict_proba(data)[:,1]\n",
    "    \n",
    "    data_XGBT = data_XGB.reshape(-1,1)\n",
    "    data_RFCT = data_RFC.reshape(-1,1)\n",
    "    data_ETCT = data_ETC.reshape(-1,1)\n",
    "    data_CBCT = data_CBC.reshape(-1,1)\n",
    "    \n",
    "    data = np.concatenate((data_XGBT, data_RFCT, data_ETCT, data_CBCT), axis=1)\n",
    "    \n",
    "    y_pred = model.predict(data)\n",
    "    y_prob = model.predict_proba(data)[:,1]\n",
    "    temp_dict = {\"Prediction: \": np.round(y_pred), \"Probability: \": y_prob }\n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fbcb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload  = x_train.iloc[0].to_dict()\n",
    "print ('{ \"payload\": ', payload, \"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d891d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.Request()\n",
    "req.json = {\"payload\":payload}\n",
    "y_req = req\n",
    "score(RFC_Stack, y_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9ab563",
   "metadata": {},
   "outputs": [],
   "source": [
    "## registering the model in Fosfor.\n",
    "model_reg = register_model(RFC_Stack,\n",
    "               score, \n",
    "               name=\"Credit_Risk_StackedRF_Classifier\", \n",
    "               description=\"Credit Risk Stacked RF Classification Model\",\n",
    "               flavour=MLModelFlavours.sklearn,\n",
    "               model_type=\"classification\",\n",
    "               #init_script=\"pip install snowflake-ml-python==1.0.11\",\n",
    "               init_script=\"pip install scikit-learn==1.2.1\",   \n",
    "               y_true=y_train,\n",
    "               y_pred=y_pred,\n",
    "               prob=y_prob,\n",
    "               features=x_train.columns,\n",
    "               input_type=\"json\", \n",
    "               explain_ai=True,\n",
    "               x_train=x_train, \n",
    "               x_test=x_train, \n",
    "               y_train=y_train.tolist(),\n",
    "               y_test=y_train.tolist(),\n",
    "               feature_names=x_train.columns.tolist(),\n",
    "               original_features=x_train.columns.tolist(),\n",
    "               feature_ids=x_train.columns,\n",
    "               kyd=True, kyd_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ffb188",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/Output/CreditRisk_StackedRFclassifier_v1.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(RFC_Stack, f) # serialize the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f8d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('model_artifacts/CreditRisk_StackedRFclassifier_v1.pkl', 'wb') as f:  # open a text file\n",
    "#    pickle.dump(RFC_Stack, f) # serialize the list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32881dd6",
   "metadata": {},
   "source": [
    "# Version 2 of Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63323bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_stk = np.concatenate((x_train_RFCT, x_train_ETCT, x_train_CBCT),axis=1)\n",
    "x_test_stk = np.concatenate(( x_test_RFCT, x_test_ETCT, x_test_CBCT),axis=1)\n",
    "\n",
    "RFC_Stack = RandomForestClassifier()\n",
    "RFC_Stack.fit(x_train_stk,y_train)\n",
    "\n",
    "y_pred_stk = RFC_Stack.predict(x_train_stk)\n",
    "y_prob_stk = RFC_Stack.predict_proba(x_train_stk)[:,1]\n",
    "\n",
    "ytest_pred_stk = RFC_Stack.predict(x_test_stk)\n",
    "ytest_prob_stk = RFC_Stack.predict_proba(x_test_stk)[:,1]\n",
    "\n",
    "y_pred_stk\n",
    "y_prob_stk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a629b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scoring_func\n",
    "def score(model, request):\n",
    "    payload_dict = request.json[\"payload\"]\n",
    "    data = pd.DataFrame(payload_dict,index=[0])\n",
    "    \n",
    "    #data_XGB = gbdt.predict(xgb.DMatrix(data))\n",
    "    data_RFC = RFC.predict_proba(data)[:,1]\n",
    "    data_ETC = ETC.predict_proba(data)[:,1]\n",
    "    data_CBC = CBC.predict_proba(data)[:,1]\n",
    "    \n",
    "    #data_XGBT = data_XGB.reshape(-1,1)\n",
    "    data_RFCT = data_RFC.reshape(-1,1)\n",
    "    data_ETCT = data_ETC.reshape(-1,1)\n",
    "    data_CBCT = data_CBC.reshape(-1,1)\n",
    "    \n",
    "    #data = np.concatenate((data_XGBT, data_RFCT, data_ETCT, data_CBCT), axis=1)\n",
    "    data = np.concatenate((data_RFCT, data_ETCT, data_CBCT), axis=1)\n",
    "    \n",
    "    y_pred = model.predict(data)\n",
    "    y_prob = model.predict_proba(data)[:,1]\n",
    "    temp_dict = {\"Prediction: \": np.round(y_pred), \"Probability: \": y_prob }\n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6bb3a2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating build time metrics\n",
      "\n",
      "Progress: ██████████████████████████████████████████████████████████████████████ 100.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb1572008b54828bff3f48eb3ab022d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<style>.grad_1{background: #2468a4;} .grad_2{ color:white; background: #2468a4;}</s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## registering the model in Fosfor with correct output (y_pred_stk, y_prob_stk.\n",
    "model_reg = register_model(RFC_Stack,\n",
    "               score, \n",
    "               name=\"Credit_Risk_StackedRF_Classifier\", \n",
    "               description=\"Credit Risk Stacked RF Classification Model\",\n",
    "               flavour=MLModelFlavours.sklearn,\n",
    "               model_type=\"classification\",\n",
    "               #init_script=\"pip install snowflake-ml-python==1.0.11\",\n",
    "               init_script=\"pip install scikit-learn==1.2.1\",   \n",
    "               y_true=y_train,\n",
    "               y_pred=y_pred_stk,\n",
    "               prob=y_prob_stk,\n",
    "               features=x_train.columns,\n",
    "               input_type=\"json\", \n",
    "               explain_ai=True,\n",
    "               x_train=x_train, \n",
    "               x_test=x_train, \n",
    "               y_train=y_train.tolist(),\n",
    "               y_test=y_train.tolist(),\n",
    "               feature_names=x_train.columns.tolist(),\n",
    "               original_features=x_train.columns.tolist(),\n",
    "               feature_ids=x_train.columns,\n",
    "               kyd=True, kyd_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c4872330",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/Output/CreditRisk_StackedRFclassifier_v2.pkl', 'wb') as f:  # open a text file\n",
    "    pickle.dump(RFC_Stack, f) # serialize the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "76a8cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('model_artifacts/CreditRisk_StackedRFclassifier_v2.pkl', 'wb') as f:  # open a text file\n",
    "#    pickle.dump(RFC_Stack, f) # serialize the list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4076d63",
   "metadata": {},
   "source": [
    "# Create Sample Dataframe/Table for Monitoring Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9f0a9fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((307511, 156), (307511,), (307511,), (307511,))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, y_pred_stk.shape, y_prob_stk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8d67b509",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48744, 156), (48744,), (48744,))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape ,  ytest_pred_stk.shape, ytest_prob_stk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c59e5800",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame,\n",
       " pandas.core.series.Series,\n",
       " numpy.ndarray,\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train), type(y_train), type(y_pred_stk), type(y_prob_stk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ec4c3e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_stk = pd.DataFrame(y_pred_stk, columns=['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ab859c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob_stk = pd.DataFrame(y_prob_stk, columns=['Probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "599c9b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(y_train, columns=['TARGET'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "37566685",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.concat([x_train, df_train, df_pred_stk, df_prob_stk], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3918ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.to_csv('/data/Output/application_train_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c8b25721",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv('/data/Output/application_train_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c26f53f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df_1 = temp_df.sample(frac = 0.7)\n",
    "temp_df_2 = temp_df.drop(temp_df_1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9d8ac34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 160)\n",
      "(215258, 160)\n",
      "(92253, 160)\n"
     ]
    }
   ],
   "source": [
    "print (temp_df.shape)\n",
    "print (temp_df_1.shape)\n",
    "print (temp_df_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f78dcb2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(temp_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab2a0221",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model=session.createDataFrame(\n",
    "        temp_df_1.values.tolist(),\n",
    "        schema=temp_df_1.columns.tolist())\n",
    "df_model.write.mode(\"overwrite\").save_as_table(\"FDC_Banking_FS.PUBLIC.CRA_APPLICATION_OUTPUT_BATCH1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec564a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model=session.createDataFrame(\n",
    "        temp_df_2.values.tolist(),\n",
    "        schema=temp_df_2.columns.tolist())\n",
    "df_model.write.mode(\"overwrite\").save_as_table(\"FDC_Banking_FS.PUBLIC.CRA_APPLICATION_OUTPUT_BATCH2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
